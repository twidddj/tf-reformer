{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/twidddj/tf-reformer/blob/master/reformer_(duplication_task).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "alXgWWk0H4pH",
    "outputId": "53c2b558-2c11-4dad-b7ae-c698302e5b79"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow 1.x selected.\n"
     ]
    }
   ],
   "source": [
    "%tensorflow_version 1.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "7WK6BgRKgS3E",
    "outputId": "37934d66-df67-4a58-901b-65917865d408"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'tf-reformer'...\n",
      "remote: Enumerating objects: 26, done.\u001b[K\n",
      "remote: Counting objects: 100% (26/26), done.\u001b[K\n",
      "remote: Compressing objects: 100% (24/24), done.\u001b[K\n",
      "remote: Total 26 (delta 1), reused 22 (delta 1), pack-reused 0\u001b[K\n",
      "Unpacking objects: 100% (26/26), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/twidddj/tf-reformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "3YDU1iBIICeT"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from time import time\n",
    "\n",
    "sys.path.append('./tf-reformer')\n",
    "from dupltask.train import DuplTaskReformer, get_sample, log_dir_tmpl, log_dir_full_attn_tmpl\n",
    "log_dir_tmpl = os.path.join('./tf-reformer/dupltask', log_dir_tmpl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "ydNEkYuY1erv",
    "outputId": "2d919152-10e3-4c95-eba2-1f36b20ca1dd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0, 33, 24, 58, 15, 33, 17, 35, 46, 22,  1, 32, 28, 61, 25, 14,  0,\n",
       "       33, 24, 58, 15, 33, 17, 35, 46, 22,  1, 32, 28, 61, 25, 14])"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_sample(64, 15) # vocab_size: 64, seq_len:32, seg_len: 15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ADGwe5KwP3ZF"
   },
   "source": [
    "# config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "i26RQFX_Pz6A",
    "outputId": "c31f8433-b8f7-4bb5-cc0d-cb6dba14cd92"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'./tf-reformer/dupltask/log_dir/lsh_seq1024_nr2_bs64'"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = 8\n",
    "d_model = 128\n",
    "d_ff = 256\n",
    "num_heads = 4\n",
    "num_blocks = 1\n",
    "vocab_size = 64\n",
    "seq_len = 1024\n",
    "seg_len = seq_len // 2 - 1\n",
    "\n",
    "num_hashes = 2\n",
    "bucket_size = 64\n",
    "\n",
    "manual_grad = False\n",
    "is_full = False\n",
    "\n",
    "if manual_grad and not log_dir_tmpl.endswith(\"_manual\"):\n",
    "    log_dir_tmpl += \"_manual\"\n",
    "if is_full:\n",
    "    log_dir = log_dir_full_attn_tmpl.format(seq_len)\n",
    "else:\n",
    "    log_dir = log_dir_tmpl.format(seq_len, num_hashes, bucket_size)    \n",
    "log_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RQN6FngOIMi_"
   },
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 496
    },
    "colab_type": "code",
    "id": "IUk62TGeIJCu",
    "outputId": "7c7ab14e-b4d4-4348-a3ea-aebb6fdbd2cc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From ./tf-reformer/transformer_modules.py:69: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From ./tf-reformer/transformer_modules.py:71: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "WARNING:tensorflow:From ./tf-reformer/models.py:62: dropout (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dropout instead.\n",
      "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/layers/core.py:271: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "WARNING:tensorflow:From ./tf-reformer/modules.py:215: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.Dense instead.\n",
      "WARNING:tensorflow:From ./tf-reformer/models.py:136: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From ./tf-reformer/models.py:140: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "xs = tf.placeholder(tf.int32, shape=[N, seq_len])\n",
    "ys = tf.slice(xs, [0, tf.shape(xs)[1]//2 + 1], [-1, -1])\n",
    "lr = tf.placeholder(tf.float32)\n",
    "\n",
    "model = DuplTaskReformer(d_model, d_ff, num_heads, vocab_size, num_blocks, seq_len, dropout_rate=0.0, is_training=True,\n",
    "                         num_hashes=num_hashes, bucket_size=bucket_size, is_full=is_full)\n",
    "loss, train_op, _ = model.train(xs, ys, lr, manual_grad=manual_grad)\n",
    "model.build_for_ar_gen(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 258
    },
    "colab_type": "code",
    "id": "bnarGZRTO27p",
    "outputId": "355f116f-71d6-4610-9eef-2e93ca22b459"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'weight_mat:0' shape=(64, 128) dtype=float32_ref>\n",
      "<tf.Variable 'num_blocks_0/multihead_lsh_attention/qk_prj/dense/kernel:0' shape=(128, 128) dtype=float32_ref>\n",
      "<tf.Variable 'num_blocks_0/multihead_lsh_attention/qk_prj/dense/bias:0' shape=(128,) dtype=float32_ref>\n",
      "<tf.Variable 'num_blocks_0/multihead_lsh_attention/dense/kernel:0' shape=(128, 128) dtype=float32_ref>\n",
      "<tf.Variable 'num_blocks_0/multihead_lsh_attention/dense/bias:0' shape=(128,) dtype=float32_ref>\n",
      "<tf.Variable 'num_blocks_0/multihead_lsh_attention/ln/beta:0' shape=(128,) dtype=float32_ref>\n",
      "<tf.Variable 'num_blocks_0/multihead_lsh_attention/ln/gamma:0' shape=(128,) dtype=float32_ref>\n",
      "<tf.Variable 'num_blocks_0/positionwise_feedforward/W1:0' shape=(128, 256) dtype=float32_ref>\n",
      "<tf.Variable 'num_blocks_0/positionwise_feedforward/B1:0' shape=(256,) dtype=float32_ref>\n",
      "<tf.Variable 'num_blocks_0/positionwise_feedforward/W2:0' shape=(256, 128) dtype=float32_ref>\n",
      "<tf.Variable 'num_blocks_0/positionwise_feedforward/B2:0' shape=(128,) dtype=float32_ref>\n",
      "<tf.Variable 'num_blocks_0/positionwise_feedforward/ln/beta:0' shape=(128,) dtype=float32_ref>\n",
      "<tf.Variable 'num_blocks_0/positionwise_feedforward/ln/gamma:0' shape=(128,) dtype=float32_ref>\n"
     ]
    }
   ],
   "source": [
    "for var in tf.trainable_variables():\n",
    "  print(var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 446
    },
    "colab_type": "code",
    "id": "1ENzn5liIV58",
    "outputId": "498711bc-3c98-46ab-8e4e-d25eb7511709"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tCheckpoint found: ./tf-reformer/dupltask/log_dir/lsh_seq1024_nr2_bs64/model.ckpt-130000\n",
      "\tINFO:tensorflow:Restoring parameters from ./tf-reformer/dupltask/log_dir/lsh_seq1024_nr2_bs64/model.ckpt-130000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-ac6c397eab10>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mit\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprev_step\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0m_xs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mget_sample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseg_len\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0m_ys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_op\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0m_xs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1e-3\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    954\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    955\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 956\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    957\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    958\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1180\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1181\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1357\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1358\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1359\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1360\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1361\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1363\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1364\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1365\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1366\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1367\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1348\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[0;32m-> 1350\u001b[0;31m                                       target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1441\u001b[0m     return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,\n\u001b[1;32m   1442\u001b[0m                                             \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1443\u001b[0;31m                                             run_metadata)\n\u001b[0m\u001b[1;32m   1444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1445\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    prev_step = model.load(sess, log_dir) or 0\n",
    "    \n",
    "    max_iter = 150000\n",
    "    losses = []\n",
    "    start = time()\n",
    "    \n",
    "    print_every = 500\n",
    "    eval_every = 1000\n",
    "    save_every = 10000\n",
    "    \n",
    "    cur_loss = np.inf\n",
    "    for it in range(prev_step+1, max_iter+1):\n",
    "        _xs = np.stack([get_sample(vocab_size, seg_len) for _ in range(N)])\n",
    "        _ys, _loss, _ = sess.run([ys, loss, train_op], feed_dict={xs:_xs, lr:1e-3})\n",
    "\n",
    "        losses.append(_loss)\n",
    "        \n",
    "        if it % print_every == 0:        \n",
    "            end = time()\n",
    "            cur_loss = np.mean(losses)\n",
    "            print(\"step:{0:} \\telapsed: {1:.2f}s \\t loss: {2:.3f}\".format(it, end-start, cur_loss))\n",
    "            losses = []\n",
    "            start = end\n",
    "\n",
    "        if cur_loss < 5 and it % eval_every == 0:\n",
    "            start_infer = time()\n",
    "            gen_data_samples = np.stack([get_sample(vocab_size, seg_len) for _ in range(1)])\n",
    "            gen_sample = model.ar_gen(sess, seg_len, samples=gen_data_samples)\n",
    "            print(\"left:\", gen_sample[0][:seg_len+1])\n",
    "            print(\"right:\", gen_sample[0][seg_len+1:])\n",
    "            \n",
    "            left_seg = gen_sample[:, 1:seg_len+1]\n",
    "            right_seg = gen_sample[:, seg_len+2:]\n",
    "            acc = np.sum(left_seg == right_seg, -1)/seg_len\n",
    "            avg_acc = np.mean(acc)\n",
    "            print(\"accuracy: {0:.4f}, elapsed: {1:.2f}s\".format(avg_acc, time()-start_infer))            \n",
    "            \n",
    "        if it % save_every == 0:\n",
    "            model.save(sess, log_dir, it)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8TSlIB85zA4t"
   },
   "source": [
    "Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "p0l6yRaYzBfx"
   },
   "outputs": [],
   "source": [
    "sample_batch_size = 1\n",
    "num_batch = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "jiujYBRWzGSQ"
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "train_nr = 2\n",
    "eval_nr = 4\n",
    "is_full = False\n",
    "\n",
    "model = DuplTaskReformer(d_model, d_ff, num_heads, vocab_size, num_blocks, seq_len, is_training=False,\n",
    "                         num_hashes=eval_nr, bucket_size=bucket_size, is_full=is_full)\n",
    "model.build_for_ar_gen(sample_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 853
    },
    "colab_type": "code",
    "id": "0_Fnws-lzNYe",
    "outputId": "fbf26586-7fc2-4a9c-bc52-984ac4e7ca3b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tCheckpoint found: ./tf-reformer/dupltask/log_dir/lsh_seq1024_nr2_bs64/model.ckpt-130000\n",
      "\tINFO:tensorflow:Restoring parameters from ./tf-reformer/dupltask/log_dir/lsh_seq1024_nr2_bs64/model.ckpt-130000\n",
      "elapsed per batch: 17.29s, estimated time: 172.93s\n",
      "left: [ 0  4 23 14 53 13  4 26 29  9 49 15 19  2 34  5 30 27 43 37 49 47 53 13\n",
      "  4 59 48 48 48 46 14 46 40  6 40 32 22 28 16 20  7 62 57 26 29 52 48 15\n",
      " 37 50 10 33 56 21 54  1 15 60 10 54 40 19 59  7 51  8 36 59 41 42 25 54\n",
      " 20 10 31 54 56 33 16 40 48 38 54 16 39 47 39 14 62 61 28  2 36 50 20 57\n",
      " 14 62  3 36 27 39  7 41 11 59 35 50 35 25 17 24 28 12  3 59 56 26 38 62\n",
      " 13 57 51  2 56 38 22 30 31 40 34 55 54 39  3 45 59 20 55 38  8 49 62 44\n",
      " 35 57 51  9 52 51 41 61 21 30  2  2 59 16 44 49 31 26 15 26  7 44 30 43\n",
      " 58 54  3 38 33 37 23 24 15 34  4 49 56 54 45 33 43 48 45 36 46 42 29 18\n",
      "  7  8  6 14 52 21 45 24 40 58  5 42 43 55 30 39 48 31 55  7 19  1 14 11\n",
      " 56 22 59 60 23 31  4  5  5  1 48 61 35 10 57 18 37  8 27  5  1 24 51 19\n",
      " 47 56 23 19 53 60 55 59  1  8 59 34  5 30 61 38 44 35 48  3 34 29 20  1\n",
      " 47 41 17 35 12  9  6 55 54 13 62  4 43 27 39 44 57  5 61  1 47 12 49 55\n",
      " 22  1  7 31  1 27 27 31  4 47 38 24 10 34 26 46  6 46 35 24 29 56 16 56\n",
      " 15 52 21 24 39 43 31 27 62 58 34 17 12  3 10 55  7 46 46 21  2  9 54 60\n",
      "  6 50 39 44 22 15 12 43 46  4  6 51 15  3 19 10 49 59 20  6  8 55 16 49\n",
      " 29 16 58 58 34  5 27 12 51 22 51 17 49 12 61 15 21 39 51 26 37 31 23 18\n",
      " 32 54 56 24  4 49 36 54 51 33 14 37  4 15  9 12 37 12 33 23 46 37  8  5\n",
      " 22 34 26 44 28 13  6 19 29 31 22 44 24 30 19 18  7 42 61 24 17 49 19 29\n",
      "  5 36 12 45 56 47 33 16 59 48 32 16 56  5  6 34 25 22 59 44 16 25 31 48\n",
      "  2 43 14 35 15 43 38 44 18 57 45 54 15 30  5 30 43 47  9 41 17 14 15 26\n",
      " 29 58 59 62 23 27 61 20 13 48 39 59 47 45 20 45 31  8 29 25 61 19 30 49\n",
      " 57 17 37 31 13 33 15 55]\n",
      "right: [ 0  4 23 14 53 13  4 26 29  9 49 15 19  2 34  5 30 27 43 37 49 47 53 13\n",
      "  4 59 48 48 48 46 14 46 40  6 40 32 22 28 16 20  7 62 57 26 29 52 48 15\n",
      " 37 50 10 33 56 21 54  1 15 60 10 54 40 19 59  7 51  8 36 59 41 42 25 54\n",
      " 20 10 31 54 56 33 16 40 48 38 54 16 39 47 39 14 62 61 28  2 36 50 20 57\n",
      " 14 62  3 36 27 39  7 41 11 59 35 50 35 25 17 24 28 12  3 59 56 26 38 62\n",
      " 13 57 51  2 56 38 22 30 31 40 34 55 54 39  3 45 59 20 55 38  8 49 62 44\n",
      " 35 57 51  9 52 51 41 61 21 30  2  2 59 16 44 49 31 26 15 26  7 44 30 43\n",
      " 58 54  3 38 33 37 23 24 15 34  4 49 56 54 45 33 43 48 45 36 46 42 29 18\n",
      "  7  8  6 14 52 21 45 24 40 58  5 42 43 55 30 39 48 31 55  7 19  1 14 11\n",
      " 56 22 59 60 23 31  4  5  5  1 48 61 35 10 57 18 37  8 27  5  1 24 51 19\n",
      " 47 56 23 19 53 60 55 59  1  8 59 34  5 30 61 38 44 35 48  3 34 29 20  1\n",
      " 47 41 17 35 12  9  6 55 54 13 62  4 43 27 39 44 57  5 61  1 47 12 49 55\n",
      " 22  1  7 31  1 27 27 31  4 47 38 24 10 34 26 46  6 46 35 24 29 56 16 56\n",
      " 15 52 21 24 39 43 31 27 62 58 34 17 12  3 10 55  7 46 46 21  2  9 54 60\n",
      "  6 50 39 44 22 15 12 43 46  4  6 51 15  3 19 10 49 59 20  6  8 55 16 49\n",
      " 29 16 58 58 34  5 27 12 51 22 51 17 49 12 61 15 21 39 51 26 37 31 23 18\n",
      " 32 54 56 24  4 49 36 54 51 33 14 37  4 15  9 12 37 12 33 23 46 37  8  5\n",
      " 22 34 26 44 28 13  6 19 29 31 22 44 24 30 19 18  7 42 61 24 17 49 19 29\n",
      "  5 36 12 45 56 47 33 16 59 48 32 16 56  5  6 34 25 22 59 44 16 25 31 48\n",
      "  2 43 14 35 15 43 38 44 18 57 45 54 15 30  5 30 43 47  9 41 17 14 15 26\n",
      " 29 58 59 62 23 27 61 20 13 48 39 59 47 45 20 45 31  8 29 25 61 19 30 49\n",
      " 57 17 37 31 13 33 15 55]\n",
      "accuracy: 0.9996, elapsed: 167.99s\n"
     ]
    }
   ],
   "source": [
    "avg_acc_arr = []\n",
    "start_infer = time()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    model.load(sess, log_dir)\n",
    "    for it in range(num_batch):\n",
    "        tmp = time()\n",
    "        \n",
    "        eval_data = np.stack([get_sample(vocab_size, seg_len) for _ in range(sample_batch_size)])\n",
    "        gen_sample = model.ar_gen(sess, seg_len, samples=eval_data)\n",
    "\n",
    "        left_seg = gen_sample[:, 1:seg_len + 1]\n",
    "        right_seg = gen_sample[:, seg_len + 2:]\n",
    "        acc = np.sum(left_seg == right_seg, -1) / seg_len\n",
    "        avg_acc = np.mean(acc)\n",
    "        avg_acc_arr.append(avg_acc)\n",
    "        if it == 0:\n",
    "            elapsed = time() - tmp\n",
    "            estimated = elapsed * num_batch\n",
    "            print(\"elapsed per batch: {0:.2f}s, estimated time: {1:.2f}s\".format(elapsed, estimated))\n",
    "\n",
    "    print(\"left:\", gen_sample[0][:seg_len + 1])\n",
    "    print(\"right:\", gen_sample[0][seg_len + 1:])\n",
    "    print(\"accuracy: {0:.4f}, elapsed: {1:.2f}s\".format(np.mean(avg_acc_arr), time() - start_infer))            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "reoY4-3tPmwa"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyM5jIvbE79susiHvja5jFDC",
   "collapsed_sections": [],
   "include_colab_link": true,
   "mount_file_id": "1ZGmQn_N1bp3D6dMuSsbf7fK8SoGirR7y",
   "name": "reformer (duplication task).ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
